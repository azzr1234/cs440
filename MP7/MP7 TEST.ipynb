{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33333333, 0.33333333, 0.33333333])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon=0.6\n",
    "decision = np.random.uniform(0, 1)\n",
    "if decision < epsilon:\n",
    "    pi = np.ones(3) / 3\n",
    "else:\n",
    "    pi = np.zeros(3)\n",
    "    pi[0] = 1.0\n",
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice([0,1,2],1,p=pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=pd.DataFrame(np.zeros((3, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=np.zeros((3,3) + (4,))[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "state=np.array([2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[state[np.newaxis]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "env = gym.make('MountainCar-v0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test():\n",
    "    def __init__(self, env,buckets):\n",
    "        self.env=env\n",
    "        self.buckets=(3,2)\n",
    "        \n",
    "    def discretize(self,obs):\n",
    "        upper_bounds = [self.env.observation_space.high[0], self.env.observation_space.high[1]]\n",
    "        lower_bounds = [self.env.observation_space.low[0], self.env.observation_space.low[1]]\n",
    "        ratios = [(obs[i] + abs(lower_bounds[i])) / (upper_bounds[i] - lower_bounds[i]) for i in range(len(obs))]\n",
    "        new_obs = [int(round((self.buckets[i] - 1) * ratios[i])) for i in range(len(obs))]\n",
    "        new_obs = [min(self.buckets[i] - 1, max(0, new_obs[i])) for i in range(len(obs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "env.reset()\n",
    "goal_steps = 200\n",
    "score_requirement = -198\n",
    "intial_games = 10000\n",
    "obs=[]\n",
    "def play_a_random_game_first():\n",
    "    for step_index in range(goal_steps):\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        obs.append(observation)\n",
    "        print(\"Step {}:\".format(step_index))\n",
    "        print(\"action: {}\".format(action))\n",
    "        print(\"observation: {}\".format(observation))\n",
    "        print(\"reward: {}\".format(reward))\n",
    "        print(\"done: {}\".format(done))\n",
    "        print(\"info: {}\".format(info))\n",
    "        if done:\n",
    "            break\n",
    "    env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0:\n",
      "action: 0\n",
      "observation: [-0.4613687  -0.00147488]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 1:\n",
      "action: 2\n",
      "observation: [-0.46230761 -0.0009389 ]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 2:\n",
      "action: 0\n",
      "observation: [-0.46470361 -0.002396  ]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 3:\n",
      "action: 0\n",
      "observation: [-0.46853903 -0.00383542]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 4:\n",
      "action: 2\n",
      "observation: [-0.47178552 -0.00324649]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 5:\n",
      "action: 0\n",
      "observation: [-0.47641905 -0.00463353]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 6:\n",
      "action: 1\n",
      "observation: [-0.48140525 -0.0049862 ]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 7:\n",
      "action: 1\n",
      "observation: [-0.48670705 -0.0053018 ]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 8:\n",
      "action: 0\n",
      "observation: [-0.49328498 -0.00657793]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 9:\n",
      "action: 2\n",
      "observation: [-0.49908995 -0.00580497]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 10:\n",
      "action: 1\n",
      "observation: [-0.50507856 -0.00598862]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 11:\n",
      "action: 0\n",
      "observation: [-0.51220601 -0.00712745]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 12:\n",
      "action: 2\n",
      "observation: [-0.51841889 -0.00621288]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 13:\n",
      "action: 0\n",
      "observation: [-0.52567062 -0.00725173]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 14:\n",
      "action: 0\n",
      "observation: [-0.5339068  -0.00823619]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 15:\n",
      "action: 0\n",
      "observation: [-0.54306569 -0.00915889]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 16:\n",
      "action: 1\n",
      "observation: [-0.55207866 -0.00901297]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 17:\n",
      "action: 0\n",
      "observation: [-0.56187829 -0.00979963]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 18:\n",
      "action: 2\n",
      "observation: [-0.57039146 -0.00851316]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 19:\n",
      "action: 0\n",
      "observation: [-0.57955483 -0.00916337]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 20:\n",
      "action: 2\n",
      "observation: [-0.5873005  -0.00774567]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 21:\n",
      "action: 1\n",
      "observation: [-0.5945713  -0.00727081]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 22:\n",
      "action: 2\n",
      "observation: [-0.60031383 -0.00574253]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 23:\n",
      "action: 2\n",
      "observation: [-0.60448606 -0.00417223]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 24:\n",
      "action: 2\n",
      "observation: [-0.60705757 -0.00257151]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 25:\n",
      "action: 1\n",
      "observation: [-0.60900966 -0.00195209]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 26:\n",
      "action: 1\n",
      "observation: [-0.61032816 -0.0013185 ]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 27:\n",
      "action: 2\n",
      "observation: [-6.10003500e-01  3.24660573e-04]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 28:\n",
      "action: 2\n",
      "observation: [-0.60803804  0.00196546]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 29:\n",
      "action: 2\n",
      "observation: [-0.60444603  0.00359201]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 30:\n",
      "action: 1\n",
      "observation: [-0.6002536   0.00419243]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 31:\n",
      "action: 1\n",
      "observation: [-0.59549131  0.00476229]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 32:\n",
      "action: 1\n",
      "observation: [-0.59019399  0.00529731]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 33:\n",
      "action: 2\n",
      "observation: [-0.58340053  0.00679346]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 34:\n",
      "action: 0\n",
      "observation: [-0.57716096  0.00623957]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 35:\n",
      "action: 2\n",
      "observation: [-0.56952139  0.00763956]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 36:\n",
      "action: 0\n",
      "observation: [-0.5625385   0.00698289]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 37:\n",
      "action: 2\n",
      "observation: [-0.55426422  0.00827428]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 38:\n",
      "action: 0\n",
      "observation: [-0.54676028  0.00750394]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 39:\n",
      "action: 1\n",
      "observation: [-0.53908276  0.00767752]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 40:\n",
      "action: 2\n",
      "observation: [-0.53028916  0.0087936 ]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 41:\n",
      "action: 1\n",
      "observation: [-0.52144538  0.00884378]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 42:\n",
      "action: 2\n",
      "observation: [-0.51161775  0.00982763]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 43:\n",
      "action: 1\n",
      "observation: [-0.50187996  0.00973779]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 44:\n",
      "action: 2\n",
      "observation: [-0.49130494  0.01057501]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 45:\n",
      "action: 0\n",
      "observation: [-0.48197175  0.00933319]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 46:\n",
      "action: 1\n",
      "observation: [-0.47294996  0.0090218 ]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 47:\n",
      "action: 2\n",
      "observation: [-0.46330657  0.00964339]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 48:\n",
      "action: 1\n",
      "observation: [-0.4541129   0.00919366]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 49:\n",
      "action: 1\n",
      "observation: [-0.44543662  0.00867628]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 50:\n",
      "action: 2\n",
      "observation: [-0.4363412   0.00909542]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 51:\n",
      "action: 0\n",
      "observation: [-0.42889275  0.00744844]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 52:\n",
      "action: 2\n",
      "observation: [-0.42114509  0.00774766]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 53:\n",
      "action: 2\n",
      "observation: [-0.41315379  0.0079913 ]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 54:\n",
      "action: 1\n",
      "observation: [-0.40597575  0.00717804]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 55:\n",
      "action: 0\n",
      "observation: [-0.40066169  0.00531406]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 56:\n",
      "action: 1\n",
      "observation: [-0.3962489   0.00441279]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 57:\n",
      "action: 1\n",
      "observation: [-0.39276816  0.00348073]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 58:\n",
      "action: 1\n",
      "observation: [-0.39024366  0.00252451]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 59:\n",
      "action: 2\n",
      "observation: [-0.38769285  0.00255081]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 60:\n",
      "action: 1\n",
      "observation: [-0.38613333  0.00155952]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 61:\n",
      "action: 1\n",
      "observation: [-0.38557582  0.00055751]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 62:\n",
      "action: 0\n",
      "observation: [-0.38702416 -0.00144834]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 63:\n",
      "action: 0\n",
      "observation: [-0.39046839 -0.00344423]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 64:\n",
      "action: 2\n",
      "observation: [-0.39388476 -0.00341637]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 65:\n",
      "action: 2\n",
      "observation: [-0.39724962 -0.00336486]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 66:\n",
      "action: 2\n",
      "observation: [-0.40053957 -0.00328995]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 67:\n",
      "action: 0\n",
      "observation: [-0.40573164 -0.00519207]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 68:\n",
      "action: 0\n",
      "observation: [-0.4127894  -0.00705777]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 69:\n",
      "action: 2\n",
      "observation: [-0.41966302 -0.00687361]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 70:\n",
      "action: 2\n",
      "observation: [-0.42630358 -0.00664056]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 71:\n",
      "action: 2\n",
      "observation: [-0.43266354 -0.00635996]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 72:\n",
      "action: 1\n",
      "observation: [-0.43969708 -0.00703355]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 73:\n",
      "action: 0\n",
      "observation: [-0.44835327 -0.00865618]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 74:\n",
      "action: 1\n",
      "observation: [-0.45756901 -0.00921574]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 75:\n",
      "action: 2\n",
      "observation: [-0.46627675 -0.00870774]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 76:\n",
      "action: 0\n",
      "observation: [-0.47641228 -0.01013554]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 77:\n",
      "action: 0\n",
      "observation: [-0.48790054 -0.01148825]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 78:\n",
      "action: 2\n",
      "observation: [-0.49865602 -0.01075548]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 79:\n",
      "action: 0\n",
      "observation: [-0.51059839 -0.01194237]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 80:\n",
      "action: 2\n",
      "observation: [-0.52163824 -0.01103985]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 81:\n",
      "action: 2\n",
      "observation: [-0.5316928  -0.01005456]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 82:\n",
      "action: 0\n",
      "observation: [-0.54268666 -0.01099386]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 83:\n",
      "action: 0\n",
      "observation: [-0.55453743 -0.01185078]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 84:\n",
      "action: 1\n",
      "observation: [-0.5661565  -0.01161907]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 85:\n",
      "action: 2\n",
      "observation: [-0.57645726 -0.01030075]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 86:\n",
      "action: 2\n",
      "observation: [-0.58536323 -0.00890597]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 87:\n",
      "action: 0\n",
      "observation: [-0.59480862 -0.00944539]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 88:\n",
      "action: 2\n",
      "observation: [-0.60272398 -0.00791537]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 89:\n",
      "action: 0\n",
      "observation: [-0.61105147 -0.00832748]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 90:\n",
      "action: 1\n",
      "observation: [-0.61873055 -0.00767909]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 91:\n",
      "action: 2\n",
      "observation: [-0.6247058  -0.00597525]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 92:\n",
      "action: 1\n",
      "observation: [-0.62993432 -0.00522852]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 93:\n",
      "action: 2\n",
      "observation: [-0.63337878 -0.00344446]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 94:\n",
      "action: 2\n",
      "observation: [-0.63501469 -0.00163591]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 95:\n",
      "action: 2\n",
      "observation: [-6.34830453e-01  1.84234307e-04]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 96:\n",
      "action: 2\n",
      "observation: [-0.63282738  0.00200308]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 97:\n",
      "action: 2\n",
      "observation: [-0.62901967  0.00380771]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 98:\n",
      "action: 2\n",
      "observation: [-0.62343442  0.00558525]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 99:\n",
      "action: 0\n",
      "observation: [-0.61811155  0.00532287]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 100:\n",
      "action: 2\n",
      "observation: [-0.61108929  0.00702226]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 101:\n",
      "action: 2\n",
      "observation: [-0.60241836  0.00867093]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 102:\n",
      "action: 2\n",
      "observation: [-0.59216178  0.01025658]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 103:\n",
      "action: 0\n",
      "observation: [-0.58239459  0.00976719]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 104:\n",
      "action: 1\n",
      "observation: [-0.57218872  0.01020587]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 105:\n",
      "action: 1\n",
      "observation: [-0.56161971  0.01056901]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 106:\n",
      "action: 2\n",
      "observation: [-0.54976617  0.01185355]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 107:\n",
      "action: 0\n",
      "observation: [-0.53871656  0.0110496 ]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 108:\n",
      "action: 0\n",
      "observation: [-0.52855362  0.01016295]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 109:\n",
      "action: 0\n",
      "observation: [-0.51935351  0.00920011]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 110:\n",
      "action: 2\n",
      "observation: [-0.50918525  0.01016827]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 111:\n",
      "action: 2\n",
      "observation: [-0.49812505  0.0110602 ]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 112:\n",
      "action: 2\n",
      "observation: [-0.48625572  0.01186933]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 113:\n",
      "action: 1\n",
      "observation: [-0.47466587  0.01158984]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 114:\n",
      "action: 0\n",
      "observation: [-0.46444171  0.01022416]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 115:\n",
      "action: 0\n",
      "observation: [-0.4556589   0.00878281]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 116:\n",
      "action: 0\n",
      "observation: [-0.44838211  0.00727678]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 117:\n",
      "action: 0\n",
      "observation: [-0.44266468  0.00571743]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 118:\n",
      "action: 2\n",
      "observation: [-0.43654831  0.00611637]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 119:\n",
      "action: 2\n",
      "observation: [-0.43007741  0.00647089]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 120:\n",
      "action: 0\n",
      "observation: [-0.42529877  0.00477865]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 121:\n",
      "action: 1\n",
      "observation: [-0.42124673  0.00405204]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 122:\n",
      "action: 0\n",
      "observation: [-0.41895033  0.0022964 ]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 123:\n",
      "action: 1\n",
      "observation: [-0.41742596  0.00152437]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 124:\n",
      "action: 0\n",
      "observation: [-4.17684491e-01 -2.58531251e-04]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 125:\n",
      "action: 0\n",
      "observation: [-0.41972408 -0.00203959]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 126:\n",
      "action: 0\n",
      "observation: [-0.42353018 -0.0038061 ]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 127:\n",
      "action: 0\n",
      "observation: [-0.42907558 -0.00554539]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 128:\n",
      "action: 2\n",
      "observation: [-0.43432043 -0.00524485]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 129:\n",
      "action: 2\n",
      "observation: [-0.4392269  -0.00490647]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 130:\n",
      "action: 2\n",
      "observation: [-0.44375941 -0.00453252]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 131:\n",
      "action: 2\n",
      "observation: [-0.44788502 -0.00412561]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 132:\n",
      "action: 1\n",
      "observation: [-0.45257361 -0.00468859]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 133:\n",
      "action: 0\n",
      "observation: [-0.45879086 -0.00621726]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 134:\n",
      "action: 0\n",
      "observation: [-0.46649112 -0.00770026]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 135:\n",
      "action: 0\n",
      "observation: [-0.4756176  -0.00912647]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 136:\n",
      "action: 0\n",
      "observation: [-0.48610269 -0.01048509]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 137:\n",
      "action: 1\n",
      "observation: [-0.49686841 -0.01076572]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 138:\n",
      "action: 2\n",
      "observation: [-0.50683439 -0.00996598]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 139:\n",
      "action: 2\n",
      "observation: [-0.51592605 -0.00909166]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 140:\n",
      "action: 2\n",
      "observation: [-0.52407525 -0.0081492 ]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 141:\n",
      "action: 2\n",
      "observation: [-0.53122088 -0.00714563]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 142:\n",
      "action: 2\n",
      "observation: [-0.53730935 -0.00608847]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 143:\n",
      "action: 2\n",
      "observation: [-0.54229502 -0.00498567]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 144:\n",
      "action: 1\n",
      "observation: [-0.54714053 -0.00484552]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 145:\n",
      "action: 0\n",
      "observation: [-0.55280964 -0.0056691 ]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 146:\n",
      "action: 1\n",
      "observation: [-0.55825994 -0.0054503 ]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 147:\n",
      "action: 1\n",
      "observation: [-0.56345075 -0.00519081]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 148:\n",
      "action: 1\n",
      "observation: [-0.56834338 -0.00489263]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 149:\n",
      "action: 1\n",
      "observation: [-0.57290144 -0.00455806]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 150:\n",
      "action: 0\n",
      "observation: [-0.57809107 -0.00518963]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 151:\n",
      "action: 1\n",
      "observation: [-0.58287383 -0.00478276]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 152:\n",
      "action: 2\n",
      "observation: [-0.58621436 -0.00334053]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 153:\n",
      "action: 1\n",
      "observation: [-0.58908804 -0.00287367]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 154:\n",
      "action: 2\n",
      "observation: [-0.59047369 -0.00138566]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 155:\n",
      "action: 1\n",
      "observation: [-0.59136115 -0.00088745]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 156:\n",
      "action: 1\n",
      "observation: [-5.91743879e-01 -3.82729813e-04]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 157:\n",
      "action: 0\n",
      "observation: [-0.59261907 -0.00087519]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 158:\n",
      "action: 1\n",
      "observation: [-5.92980306e-01 -3.61233000e-04]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 159:\n",
      "action: 1\n",
      "observation: [-5.92824927e-01  1.55379235e-04]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 160:\n",
      "action: 2\n",
      "observation: [-0.59115408  0.00167085]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 161:\n",
      "action: 0\n",
      "observation: [-0.58998002  0.00117405]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 162:\n",
      "action: 2\n",
      "observation: [-0.58731139  0.00266863]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 163:\n",
      "action: 2\n",
      "observation: [-0.58316782  0.00414357]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 164:\n",
      "action: 0\n",
      "observation: [-0.57957986  0.00358796]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 165:\n",
      "action: 1\n",
      "observation: [-0.57557401  0.00400585]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 166:\n",
      "action: 2\n",
      "observation: [-0.57017992  0.00539409]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 167:\n",
      "action: 2\n",
      "observation: [-0.56343761  0.00674231]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 168:\n",
      "action: 0\n",
      "observation: [-0.55739722  0.00604039]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 169:\n",
      "action: 1\n",
      "observation: [-0.55110377  0.00629344]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 170:\n",
      "action: 1\n",
      "observation: [-0.54460427  0.0064995 ]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 171:\n",
      "action: 2\n",
      "observation: [-0.53694734  0.00765694]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 172:\n",
      "action: 2\n",
      "observation: [-0.52819032  0.00875702]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 173:\n",
      "action: 1\n",
      "observation: [-0.51939886  0.00879146]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 174:\n",
      "action: 0\n",
      "observation: [-0.5116389   0.00775996]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 175:\n",
      "action: 2\n",
      "observation: [-0.50296862  0.00867028]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 176:\n",
      "action: 1\n",
      "observation: [-0.49445297  0.00851565]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 177:\n",
      "action: 1\n",
      "observation: [-0.48615563  0.00829734]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 178:\n",
      "action: 1\n",
      "observation: [-0.47813853  0.0080171 ]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 179:\n",
      "action: 0\n",
      "observation: [-0.47146132  0.00667721]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 180:\n",
      "action: 2\n",
      "observation: [-0.46417355  0.00728777]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 181:\n",
      "action: 2\n",
      "observation: [-0.45632911  0.00784444]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 182:\n",
      "action: 2\n",
      "observation: [-0.44798578  0.00834333]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 183:\n",
      "action: 0\n",
      "observation: [-0.44120469  0.00678109]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 184:\n",
      "action: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation: [-0.43403529  0.0071694 ]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 185:\n",
      "action: 1\n",
      "observation: [-0.42752956  0.00650573]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 186:\n",
      "action: 0\n",
      "observation: [-0.42273441  0.00479515]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 187:\n",
      "action: 2\n",
      "observation: [-0.41768426  0.00505015]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 188:\n",
      "action: 0\n",
      "observation: [-0.41441516  0.00326909]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 189:\n",
      "action: 2\n",
      "observation: [-0.41095038  0.00346478]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 190:\n",
      "action: 1\n",
      "observation: [-0.40831447  0.00263591]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 191:\n",
      "action: 0\n",
      "observation: [-0.40752606  0.00078841]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 192:\n",
      "action: 1\n",
      "observation: [-4.07590709e-01 -6.46476937e-05]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 193:\n",
      "action: 0\n",
      "observation: [-0.40950796 -0.00191725]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 194:\n",
      "action: 1\n",
      "observation: [-0.41226428 -0.00275632]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 195:\n",
      "action: 2\n",
      "observation: [-0.41484017 -0.00257589]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 196:\n",
      "action: 2\n",
      "observation: [-0.41721736 -0.00237719]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 197:\n",
      "action: 1\n",
      "observation: [-0.42037893 -0.00316157]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 198:\n",
      "action: 1\n",
      "observation: [-0.42430234 -0.00392341]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "Step 199:\n",
      "action: 1\n",
      "observation: [-0.4289595  -0.00465716]\n",
      "reward: -1.0\n",
      "done: True\n",
      "info: {'TimeLimit.truncated': True}\n"
     ]
    }
   ],
   "source": [
    "play_a_random_game_first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "obslist=obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = np.random.choice(env.action_space.n,1,p=pi)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-6.00346416e-01, -4.32624439e-04]), -1.0, False, {})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "obs, reward, done, info = env.step(action)\n",
    "obs, reward, done, info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.00346416e-01, -4.32624439e-04])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upperbounds is  [0.6, 0.07]\n",
      "lowerbounds is [-1.2, -0.07]\n",
      "[0.3331408934431165, 0.4969098254496985]\n"
     ]
    }
   ],
   "source": [
    "buckets=(100,100)\n",
    "upper_bounds = [env.observation_space.high[0], env.observation_space.high[1]]\n",
    "print('upperbounds is ',upper_bounds)\n",
    "lower_bounds = [env.observation_space.low[0], env.observation_space.low[1]]\n",
    "print('lowerbounds is', lower_bounds)\n",
    "ratios = [(obs[i] + abs(lower_bounds[i])) / (upper_bounds[i] - lower_bounds[i]) for i in range(len(obs))]\n",
    "print(ratios)\n",
    "new_obs = [int(round((buckets[i] - 1) * ratios[i])) for i in range(len(obs))]\n",
    "new_obs = [min(buckets[i] - 1, max(0, new_obs[i])) for i in range(len(obs))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33, 49]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.high[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(2,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=np.zeros((3,3) + (4,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1,3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.array([0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.array([[1,2,3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_obs\n",
    "new_obs=np.array(new_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_obs[np.newaxis][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(np.array([10, 11, 12, 13, 10, 15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env=gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "type(env.step(0)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
